{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KASPI BANK TASK 1 SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\u0443\\u0441\\u043b\\u043e\\u0432\\u0438\\u044f', u'train', u'test']\n"
     ]
    }
   ],
   "source": [
    "file_name = 'task2.xlsx'\n",
    "xl = pd.ExcelFile(file_name)\n",
    "print(xl.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SHEET = xl.parse(u'train')\n",
    "TEST_SHEET = xl.parse(u'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 132)\n",
      "(10000, 131)\n"
     ]
    }
   ],
   "source": [
    "print(TRAIN_SHEET.shape)\n",
    "print(TEST_SHEET.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "trainLength = len(TRAIN_SHEET['NUM'])\n",
    "testLength = len(TEST_SHEET['NUM'])\n",
    "print(trainLength)\n",
    "print(testLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SHEET['TARGET'] = pd.Series(np.random.randn(testLength), index=TEST_SHEET.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DATA = pd.concat([TRAIN_SHEET, TEST_SHEET], ignore_index=True)\n",
    "MAIN_DATA[MAIN_DATA.select_dtypes(['object']).columns] = MAIN_DATA.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n",
    "cat_columns = MAIN_DATA.select_dtypes(['category']).columns\n",
    "MAIN_DATA[cat_columns] = MAIN_DATA[cat_columns].apply(lambda x: x.cat.codes)\n",
    "DATA = MAIN_DATA.fillna(MAIN_DATA.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(DATA.drop('TARGET', axis = True).drop('NUM', axis = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_VAL_DATA = DATA[:trainLength]\n",
    "TEST_DATA = (DATA[trainLength:]).drop('NUM', axis=True).drop('TARGET', axis=True)\n",
    "TEST_NORMALIZED_DATA = scaler.transform(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = TRAIN_VAL_DATA.drop('NUM', axis = True).drop('TARGET', axis = True)\n",
    "Y = TRAIN_VAL_DATA['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Y = []\n",
    "for item in Y:\n",
    "    tmp = []\n",
    "    if(item == 1.0):\n",
    "        tmp = [0.0 , 1.0]\n",
    "    else:\n",
    "        tmp = [1.0 , 0.0]\n",
    "    new_Y.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Y = np.array(new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.FloatTensor(X_norm)\n",
    "Y_tensor = torch.FloatTensor(new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batches = X_tensor.split(40)\n",
    "Y_batches = Y_tensor.split(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, nlabel):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(130, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "classifier = Classifier(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10000] Loss: 0.030\n",
      "[1001/10000] Loss: 0.005\n",
      "[2001/10000] Loss: 0.005\n",
      "[3001/10000] Loss: 0.005\n",
      "[4001/10000] Loss: 0.004\n",
      "[5001/10000] Loss: 0.004\n",
      "[6001/10000] Loss: 0.004\n",
      "[7001/10000] Loss: 0.004\n",
      "[8001/10000] Loss: 0.004\n",
      "[9001/10000] Loss: 0.004\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(classifier.parameters())\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=1e-4)\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    for labels, samples in zip(Y_batches, X_batches):\n",
    "        input_datas = Variable(samples)\n",
    "        input_labels = Variable(labels)\n",
    "        output = classifier(input_datas)\n",
    "        loss = criterion(output, input_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.mean())\n",
    "    if epoch % 1000==0:\n",
    "        print('[%d/%d] Loss: %.3f' % (epoch+1, epochs, np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " -14.8018   15.4912\n",
      " 236.8300 -251.1372\n",
      " -27.5599   29.7573\n",
      " 195.6243 -210.0303\n",
      "-156.9685  168.4965\n",
      "  14.6241  -16.0722\n",
      "  26.4513  -27.6635\n",
      "  21.4839  -23.1648\n",
      " 162.4092 -172.4937\n",
      "  25.0294  -25.5903\n",
      "-102.0571  109.8498\n",
      " -27.9657   28.9878\n",
      " -21.6309   23.0183\n",
      " -25.6304   26.5020\n",
      "  75.8059  -82.1391\n",
      "  13.6559  -15.8104\n",
      " 181.1954 -192.9361\n",
      "  66.7367  -71.5015\n",
      " 131.6038 -142.3121\n",
      " 116.4446 -125.0342\n",
      "   5.9431   -6.2896\n",
      "  35.3527  -38.4012\n",
      "  22.7954  -24.4426\n",
      "  95.3763 -101.9027\n",
      " 210.4176 -222.5711\n",
      " 144.9043 -156.4185\n",
      "-256.6062  272.3921\n",
      " -18.5455   19.3113\n",
      " 537.3000 -565.9764\n",
      " -12.3588   14.3003\n",
      " 315.2156 -340.3169\n",
      " 207.9001 -220.6423\n",
      "  48.4231  -51.7094\n",
      "  76.3449  -81.5526\n",
      "  51.4271  -54.6342\n",
      " 144.5528 -158.2618\n",
      " 180.0813 -192.7925\n",
      "-240.9494  257.8958\n",
      "  14.1040  -11.4442\n",
      " -14.2782   16.1731\n",
      "[torch.FloatTensor of size 40x2]\n",
      "\n",
      "Variable containing:\n",
      "    0     1\n",
      "    1     0\n",
      "    0     1\n",
      "    1     0\n",
      "    0     1\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    0     1\n",
      "    0     1\n",
      "    0     1\n",
      "    0     1\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    0     1\n",
      "    0     1\n",
      "    1     0\n",
      "    0     1\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    1     0\n",
      "    0     1\n",
      "    1     0\n",
      "    0     1\n",
      "[torch.FloatTensor of size 40x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "print(input_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier.state_dict(), './classifier-SGD-10000.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor =  torch.FloatTensor(TEST_NORMALIZED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(2)\n",
    "classifier.load_state_dict(torch.load('./classifier-SGD-10000.pth'))\n",
    "classifier.eval()\n",
    "input_test_datas = Variable(X_test_tensor)\n",
    "predict = classifier(input_test_datas).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict\n",
    "answer = []\n",
    "for item, num in zip(predict, range(30000, 40000)):\n",
    "    tmp = []\n",
    "    if(item[0] > item[1]):\n",
    "        tmp = [num, 0]\n",
    "    else:\n",
    "        tmp = [num, 1]\n",
    "    answer.append(tmp)\n",
    "answer = np.array(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame (answer, columns=['NUM','TARGET'])\n",
    "\n",
    "filepath = 'output-2.xlsx'\n",
    "\n",
    "df.to_excel(filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
